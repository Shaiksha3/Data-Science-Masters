{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d8aa35-271e-402f-9f6e-090c27435975",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa4761-8819-4459-a1e2-0a53b10132cf",
   "metadata": {},
   "source": [
    "1. simple linear regression models the relationship between a dependent variable and a single independent variable, while multiple linear regression models the relationship between a dependent variable and multiple independent variables. Simple linear regression uses a straight line to represent the relationship, while multiple linear regression uses a hyperplane in a higher-dimensional space.\n",
    "\n",
    "2. eg:simple linear regression:\n",
    "\n",
    "          to analyze the relationship between the number of hours studied (independent variable) and the exam score achieved (dependent variable) for a group of students\n",
    "          \n",
    "3. eg:multiple linear regression:\n",
    "\n",
    "         Suppose we want to predict the house price (dependent variable) based on various factors such as the area of the house, the number of bedrooms, and the age of the house (independent variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0028ca-a119-4106-ac00-6078f9b0f52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b068a0f-24eb-46bd-896d-07c5a38154af",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ec9ff-c15a-4bb6-8960-d70f87a0d369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3809b27b-7827-4e99-b043-a1d48793ab95",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Linearity: The relationship between the independent variables and the dependent variable is assumed to be linear. This means that the effect of each independent variable on the dependent variable is constant across different values of the independent variables.\n",
    "\n",
    "2. Independence: The observations in the dataset are assumed to be independent of each other. This assumption implies that there is no correlation or dependency between the residuals (the differences between the observed and predicted values) of the regression model.\n",
    "\n",
    "3. Homoscedasticity: Homoscedasticity assumes that the residuals have constant variance across different levels of the independent variables. In other words, the spread of the residuals should be consistent as the values of the independent variables change. Violations of this assumption can lead to heteroscedasticity, where the spread of the residuals varies systematically.\n",
    "\n",
    "4. Normality: The residuals of the regression model should follow a normal distribution. This assumption allows for valid statistical inference and hypothesis testing. Departures from normality can affect the accuracy of p-values, confidence intervals, and other statistical metrics.\n",
    "\n",
    "5. No Multicollinearity: The independent variables should not be highly correlated with each other. Multicollinearity can make it challenging to determine the individual effects of the independent variables on the dependent variable and can lead to unstable coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7d1e5-760f-4473-9e6e-c4d1f849d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed392a3b-7cae-45e5-8e21-eb0e0cbe3d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey shaikshavali how are you doing \n"
     ]
    }
   ],
   "source": [
    "print(\"hey shaikshavali how are you doing \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c300c7-92cb-48dc-862e-47a6e9251192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa45dba3-06ba-48e6-9dd7-b4d87084bdcd",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013c23a-3930-4a77-95bc-efb64b17edb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7afb17ea-22e0-4bde-8573-d88d907623bb",
   "metadata": {},
   "source": [
    "1. Intercept (β₀):\n",
    "The intercept (β₀) represents the value of the dependent variable when all independent variables are zero. It is the point where the regression line crosses the y-axis.\n",
    "\n",
    "2. Slope (β₁, β₂, β₃, ...):\n",
    "The slope coefficients (β₁, β₂, β₃, ...) represent the change in the dependent variable associated with a one-unit change in the corresponding independent variable, holding all other independent variables constant. The slope indicates the direction (positive or negative) and magnitude of the impact that each independent variable has on the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24db491-f06e-4b2a-b78a-8bf7bcafdf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "921433ba-4eac-4b76-8dac-ece2cd720ab0",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b1913-c5d2-4486-8cd6-daa79a2bc679",
   "metadata": {},
   "source": [
    "1. we get gradient decent when a graph is drawn between cost function and coefficients \n",
    "\n",
    "2. It is used to find gradient which is used in convergence algorithm \n",
    "\n",
    "3. it plays an important role in deciding the global minima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9c9c3-c4c2-4bc3-85aa-810713893478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40f2984a-6ae5-47d2-9824-2132ce0043aa",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "\n",
    "1. Multiple linear regression is an extension of simple linear regression that allows for the modeling of the relationship between a dependent variable and multiple independent variables. In multiple linear regression, the goal is to find the best-fit hyperplane in a higher-dimensional space that minimizes the sum of squared differences between the observed data points and the predicted values on the hyperplane.\n",
    "\n",
    "The multiple linear regression model can be represented by the following equation:\n",
    "\n",
    "Y = β₀ + β₁X₁ + β₂X₂ + ... + βₚ*Xₚ + ε\n",
    "\n",
    "\n",
    "2. The main difference between multiple linear regression and simple linear regression lies in the number of independent variables considered. Simple linear regression involves only one independent variable, resulting in a linear relationship represented by a straight line in a two-dimensional space. On the other hand, multiple linear regression accommodates multiple independent variables, leading to a hyperplane representation in a higher-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbb2f5-eea5-40cc-adc3-95f803c2dfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05391957-8cb0-43a7-bb56-42f3aadc0d4c",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "\n",
    "\n",
    "1. Multicollinearity refers to a high correlation or linear relationship between two or more independent variables in a multiple linear regression model. It poses a problem because it can make it difficult to separate the individual effects of the correlated variables on the dependent variable. Multicollinearity can lead to unstable coefficient estimates, reduced model interpretability, and incorrect statistical inferences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0d7e4-0167-4232-800e-5e3cca66a7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06f9fa48-965f-4e0a-8e91-98b4b1f3367e",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "\n",
    "1. Polynomial regression is an extension of linear regression that allows for modeling non-linear relationships between the dependent variable and the independent variable(s). While linear regression assumes a linear relationship, polynomial regression captures more complex patterns by introducing polynomial terms of higher degrees.\n",
    "\n",
    "The polynomial regression model can be represented by the following equation:\n",
    "\n",
    "Y = β₀ + β₁X + β₂X² + ... + βₙ*Xⁿ + ε\n",
    "\n",
    "\n",
    "2. The key difference between linear regression and polynomial regression lies in the functional form of the relationship between the independent and dependent variables. Linear regression assumes a straight line relationship, while polynomial regression allows for curved or non-linear relationships by including polynomial terms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee64a3-3f18-4486-869c-596ccc14eb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d8c2e56-7ef7-4af4-ae19-29b9240dd488",
   "metadata": {},
   "source": [
    "What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
